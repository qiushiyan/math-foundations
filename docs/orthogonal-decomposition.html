<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.1 Orthogonal decomposition | Mathematical Notes for Machine Learning</title>
  <meta name="description" content="4.1 Orthogonal decomposition | Mathematical Notes for Machine Learning" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="4.1 Orthogonal decomposition | Mathematical Notes for Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="enixam/math-foundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.1 Orthogonal decomposition | Mathematical Notes for Machine Learning" />
  
  
  

<meta name="author" content="Qiushi Yan" />


<meta name="date" content="2020-07-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="orthogonality.html"/>
<link rel="next" href="vector-calculus.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Math foundations in Machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Linear Algebra</b></span></li>
<li class="chapter" data-level="1" data-path="matrix-algebra.html"><a href="matrix-algebra.html"><i class="fa fa-check"></i><b>1</b> Matrix Algebra</a><ul>
<li class="chapter" data-level="1.1" data-path="elemetary-matrix-and-row-operations.html"><a href="elemetary-matrix-and-row-operations.html"><i class="fa fa-check"></i><b>1.1</b> Elemetary matrix and row operations</a></li>
<li class="chapter" data-level="1.2" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html"><i class="fa fa-check"></i><b>1.2</b> Matrix multiplication</a></li>
<li class="chapter" data-level="1.3" data-path="arithmetic-properties.html"><a href="arithmetic-properties.html"><i class="fa fa-check"></i><b>1.3</b> Arithmetic properties</a><ul>
<li class="chapter" data-level="1.3.1" data-path="arithmetic-properties.html"><a href="arithmetic-properties.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>1.3.1</b> Inverse of a matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="lu-factorization.html"><a href="lu-factorization.html"><i class="fa fa-check"></i><b>1.4</b> LU factorization</a></li>
<li class="chapter" data-level="1.5" data-path="determinants.html"><a href="determinants.html"><i class="fa fa-check"></i><b>1.5</b> Determinants</a><ul>
<li class="chapter" data-level="1.5.1" data-path="determinants.html"><a href="determinants.html#properties-of-determinants"><i class="fa fa-check"></i><b>1.5.1</b> Properties of determinants</a></li>
<li class="chapter" data-level="1.5.2" data-path="determinants.html"><a href="determinants.html#cramers-rule"><i class="fa fa-check"></i><b>1.5.2</b> Cramer’s rule</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="matrix-multiplication-as-linear-transformation.html"><a href="matrix-multiplication-as-linear-transformation.html"><i class="fa fa-check"></i><b>1.6</b> Matrix multiplication as linear transformation</a></li>
<li class="chapter" data-level="1.7" data-path="special-matrices-and-their-properties.html"><a href="special-matrices-and-their-properties.html"><i class="fa fa-check"></i><b>1.7</b> Special matrices and their properties</a><ul>
<li class="chapter" data-level="1.7.1" data-path="special-matrices-and-their-properties.html"><a href="special-matrices-and-their-properties.html#orthogonal-matrices"><i class="fa fa-check"></i><b>1.7.1</b> Orthogonal matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="vector-spaces.html"><a href="vector-spaces.html"><i class="fa fa-check"></i><b>2</b> Vector spaces</a><ul>
<li class="chapter" data-level="2.1" data-path="four-subspaces.html"><a href="four-subspaces.html"><i class="fa fa-check"></i><b>2.1</b> Four subspaces</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eigenvalues-and-and-eigenvectors.html"><a href="eigenvalues-and-and-eigenvectors.html"><i class="fa fa-check"></i><b>3</b> Eigenvalues and and eigenvectors</a><ul>
<li class="chapter" data-level="3.1" data-path="diagnolization.html"><a href="diagnolization.html"><i class="fa fa-check"></i><b>3.1</b> Diagnolization</a></li>
<li class="chapter" data-level="3.2" data-path="eigenvectors-and-linear-transformations.html"><a href="eigenvectors-and-linear-transformations.html"><i class="fa fa-check"></i><b>3.2</b> Eigenvectors and linear transformations</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="orthogonality.html"><a href="orthogonality.html"><i class="fa fa-check"></i><b>4</b> Orthogonality</a><ul>
<li class="chapter" data-level="4.1" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html"><i class="fa fa-check"></i><b>4.1</b> Orthogonal decomposition</a><ul>
<li class="chapter" data-level="4.1.1" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#orthogonal-complements"><i class="fa fa-check"></i><b>4.1.1</b> Orthogonal complements</a></li>
<li class="chapter" data-level="4.1.2" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#orthogonal-sets-and-orthogonal-basis"><i class="fa fa-check"></i><b>4.1.2</b> Orthogonal sets and orthogonal basis</a></li>
<li class="chapter" data-level="4.1.3" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#orthogonal-decomposition-1"><i class="fa fa-check"></i><b>4.1.3</b> Orthogonal decomposition</a></li>
<li class="chapter" data-level="4.1.4" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#best-approximation"><i class="fa fa-check"></i><b>4.1.4</b> Best approximation</a></li>
<li class="chapter" data-level="4.1.5" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#orthonormal-sets-and-orthogonal-matrices"><i class="fa fa-check"></i><b>4.1.5</b> Orthonormal sets and orthogonal matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vector-calculus.html"><a href="vector-calculus.html"><i class="fa fa-check"></i><b>5</b> Vector calculus</a></li>
<li class="chapter" data-level="6" data-path="symmetric-matrices-and-quadratic-forms.html"><a href="symmetric-matrices-and-quadratic-forms.html"><i class="fa fa-check"></i><b>6</b> Symmetric matrices and quadratic forms</a></li>
<li class="part"><span><b>II Calculus</b></span></li>
<li class="chapter" data-level="7" data-path="taylor-series-and-expansion.html"><a href="taylor-series-and-expansion.html"><i class="fa fa-check"></i><b>7</b> Taylor series and expansion</a></li>
<li class="part"><span><b>III Applications</b></span></li>
<li class="chapter" data-level="8" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>8</b> Linear models</a><ul>
<li class="chapter" data-level="8.1" data-path="least-square-estimation.html"><a href="least-square-estimation.html"><i class="fa fa-check"></i><b>8.1</b> Least square estimation</a></li>
<li class="chapter" data-level="8.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>8.2</b> Maximum likelihood estimation</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="principle-component-analysis.html"><a href="principle-component-analysis.html"><i class="fa fa-check"></i><b>9</b> Principle component analysis</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li>
  <a href="https://github.com/rstudio/bookdown" target="blank">Written with bookdown</a>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematical Notes for Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="orthogonal-decomposition" class="section level2">
<h2><span class="header-section-number">4.1</span> Orthogonal decomposition</h2>
<div id="orthogonal-complements" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Orthogonal complements</h3>
<p>if vector <span class="math inline">\(\boldsymbol{v}\)</span> is orthogonal to every vector in a subspace <span class="math inline">\(W\)</span> of <span class="math inline">\(\mathbb{R^n}\)</span>, then <span class="math inline">\(\boldsymbol{v}\)</span> is said to be orthogonal to <span class="math inline">\(W\)</span>. The subspace that contains the set of vectors that are orthogonal to <span class="math inline">\(W\)</span> is called the <strong>orthogonal complement</strong>, denoted by <span class="math inline">\(W^{\perp}\)</span>.</p>
<p>This corresponds to discussions in <a href="four-subspaces.html#four-subspaces">2.1</a>, where</p>
<p><span class="math display">\[
(\text{row} A)^{\perp} = \text{Nul} A \\
(\text{col} A)^{\perp} = \text{Nul} A^T
\]</span></p>
</div>
<div id="orthogonal-sets-and-orthogonal-basis" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Orthogonal sets and orthogonal basis</h3>
<p>An orthogonal set is a set of vectors
<span class="math inline">\(\{\boldsymbol{u_1}, \dots, \boldsymbol{u_p}\}\)</span> in <span class="math inline">\(\mathbb{R^n}\)</span>, in which each pair of distinct vectors is orthogonal: <span class="math inline">\(\boldsymbol{u_i}^{T} \boldsymbol{u_j} = 0 \quad i\not = j\)</span>. Note that the set do not necessarily span the whole <span class="math inline">\(\mathbb{R^n}\)</span>, but a subspace <span class="math inline">\(W\)</span>.</p>
<p>Since vectors in orthogonal sets is mutually perpendicular, they must also be linearly independent and could form a basis for a subspace <span class="math inline">\(W\)</span>. In such case, they are called <strong>orthogonal basis</strong>.</p>
<p>There is a particular advantage in using orthogonal basis rather than other basis, because we can find a easy representation of any vector in <span class="math inline">\(W\)</span>.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-1" class="theorem"><strong>Theorem 1.1  </strong></span>For each <span class="math inline">\(\boldsymbol{y}\)</span> in <span class="math inline">\(W\)</span>, we have the following linear combination</p>
<p><span class="math display">\[
y = c_1\boldsymbol{u_1} + \cdots + c_p\boldsymbol{u_p}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
c_i = \frac{\boldsymbol{y} \cdot \boldsymbol{u_i}}{\boldsymbol{u_i} \cdot \boldsymbol{u_i}} \quad i = 1, \cdots, p
\]</span></p>
where <span class="math inline">\(\{\boldsymbol{u_1}, \dots, \boldsymbol{u_p}\}\)</span> is an orthogonal basis.
</div>

<p><strong>Proof</strong></p>
<p><span class="math display">\[
\begin{split}
\boldsymbol{u_1} \cdot \boldsymbol{y} &amp;= \boldsymbol{u_1} \cdot (c_1\boldsymbol{u_1} + \cdots + c_p\boldsymbol{u_p}) \\
  &amp;= c_1 \boldsymbol{u_1} \cdot \boldsymbol{u_1}
\end{split}
\]</span>
So:</p>
<p><span class="math display">\[
c_1 = \frac{\boldsymbol{u_1} \cdot \boldsymbol{y}}{\boldsymbol{u_1} \cdot \boldsymbol{u_1}}
\]</span></p>
<p>Derivations for other <span class="math inline">\(c_i\)</span> is similar.</p>
</div>
<div id="orthogonal-decomposition-1" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Orthogonal decomposition</h3>
<p><strong>Orthogonal decomposition</strong> split <span class="math inline">\(\boldsymbol{y}\)</span> in <span class="math inline">\(\mathbb{R^n}\)</span> into two vectors, one in <span class="math inline">\(W\)</span> and one in its orthogonal compliment <span class="math inline">\(W^{\perp}\)</span>. The trick is to use <span class="math inline">\(\hat{\boldsymbol{y}}\)</span> as <span class="math inline">\(\boldsymbol{y}\)</span>’s projection onto <span class="math inline">\(W\)</span>, which can be represented as illustrated in <a href="orthogonal-decomposition.html#orthogonal-sets-and-orthogonal-basis">4.1.2</a>, and the other term, often referred to as error term in statistics, is simply <span class="math inline">\(\boldsymbol{y}- \hat{\boldsymbol{y}}\)</span>.</p>
<p><span class="math display">\[
\boldsymbol{y} = \hat{\boldsymbol{y}} + \boldsymbol{z}= c_1\boldsymbol{u_1} + \cdots + c_p\boldsymbol{u_p} + \boldsymbol{z} 
\]</span></p>
<p>Where</p>
<p><span class="math display">\[
c_i = \frac{\boldsymbol{y} \cdot \boldsymbol{u}_i}{\boldsymbol{u}_i \cdot \boldsymbol{u}_i}\boldsymbol{u}_i \quad i = 1, \cdots, p 
\]</span></p>
</div>
<div id="best-approximation" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Best approximation</h3>

<div class="theorem">
<p><span id="thm:best-approximation" class="theorem"><strong>Theorem 4.1  (The Best Approximation Theorem)  </strong></span>Given <span class="math inline">\(\boldsymbol{y}\)</span> be any vector in <span class="math inline">\(\mathbb{R^n}\)</span>, with its subspace <span class="math inline">\(W\)</span>, let <span class="math inline">\(\hat{\boldsymbol{y}}\)</span> be the orthogonal projection of <span class="math inline">\(\boldsymbol{y}\)</span> onto <span class="math inline">\(W\)</span>. Then <span class="math inline">\(\hat{\boldsymbol{y}}\)</span> is the closest point in <span class="math inline">\(W\)</span> to <span class="math inline">\(\boldsymbol{y}\)</span> in the sense that</p>
<span class="math display">\[
||\boldsymbol{y} - \hat{\boldsymbol{y}}|| \le ||\boldsymbol{y} - \boldsymbol{v}||
\]</span>
</div>

<p><strong>PROOF</strong></p>
<p>Take <span class="math inline">\(\boldsymbol{v}\)</span> distinct from <span class="math inline">\(\hat{\boldsymbol{y}}\)</span> in <span class="math inline">\(W\)</span>, we know that <span class="math inline">\(\boldsymbol{y} - \hat{\boldsymbol{y}}\)</span> is perpendicular to <span class="math inline">\(\boldsymbol{v}\)</span>. According to Pythoagorean theorem, we have</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="images/best-approximation.png" alt="figure from page p352, ch6 [@lay2006-3]" width="150%" />
<p class="caption">
Figure 4.1: figure from page p352, ch6 <span class="citation">(Lay <a href="references.html#ref-lay2006-3" role="doc-biblioref">2006</a>)</span>
</p>
</div>
<p><span class="math display">\[
||\boldsymbol{y}-  \boldsymbol{v}||^2 = ||\boldsymbol{\hat{y}} - \boldsymbol{v}||^2 + ||\boldsymbol{y} -\boldsymbol{\hat{y}}||^2 
\]</span>
When <span class="math inline">\(\boldsymbol{v}\)</span> is distinct from <span class="math inline">\(\boldsymbol{\hat{y}}\)</span>, <span class="math inline">\(||\boldsymbol{\hat{y}} - \boldsymbol{v}||^2\)</span> is non-negative, so the error term of choosing <span class="math inline">\(\boldsymbol{v}\)</span> is always larger than that of the orthogonal projection <span class="math inline">\(\boldsymbol{\hat{y}}\)</span>.</p>
</div>
<div id="orthonormal-sets-and-orthogonal-matrices" class="section level3">
<h3><span class="header-section-number">4.1.5</span> Orthonormal sets and orthogonal matrices</h3>
<p>An orthogonal set whose components are all unit vectors are said to be <strong>orthonormal</strong> sets.</p>

</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="orthogonality.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="vector-calculus.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/enixam/math-foundations/edit/master/orthogonality.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
