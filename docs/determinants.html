<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.4 Determinants | Mathematical Notes for Machine Learning</title>
  <meta name="description" content="1.4 Determinants | Mathematical Notes for Machine Learning" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="1.4 Determinants | Mathematical Notes for Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="enixam/math-foundations" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.4 Determinants | Mathematical Notes for Machine Learning" />
  
  
  

<meta name="author" content="Qiushi Yan" />


<meta name="date" content="2020-07-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lu-factorization.html"/>
<link rel="next" href="trace.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Math foundations in Machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Linear Algebra</b></span></li>
<li class="chapter" data-level="1" data-path="matrix-basics.html"><a href="matrix-basics.html"><i class="fa fa-check"></i><b>1</b> Matrix basics</a><ul>
<li class="chapter" data-level="1.1" data-path="matrix-multiplication.html"><a href="matrix-multiplication.html"><i class="fa fa-check"></i><b>1.1</b> Matrix multiplication</a></li>
<li class="chapter" data-level="1.2" data-path="elemetary-matrix-and-row-operations.html"><a href="elemetary-matrix-and-row-operations.html"><i class="fa fa-check"></i><b>1.2</b> Elemetary matrix and row operations</a></li>
<li class="chapter" data-level="1.3" data-path="lu-factorization.html"><a href="lu-factorization.html"><i class="fa fa-check"></i><b>1.3</b> LU factorization</a></li>
<li class="chapter" data-level="1.4" data-path="determinants.html"><a href="determinants.html"><i class="fa fa-check"></i><b>1.4</b> Determinants</a><ul>
<li class="chapter" data-level="1.4.1" data-path="determinants.html"><a href="determinants.html#cofactor-expansion"><i class="fa fa-check"></i><b>1.4.1</b> Cofactor expansion</a></li>
<li class="chapter" data-level="1.4.2" data-path="determinants.html"><a href="determinants.html#geometric-interpretation-of-determinant"><i class="fa fa-check"></i><b>1.4.2</b> Geometric interpretation of determinant</a></li>
<li class="chapter" data-level="1.4.3" data-path="determinants.html"><a href="determinants.html#properties-of-determinant"><i class="fa fa-check"></i><b>1.4.3</b> Properties of determinant</a></li>
<li class="chapter" data-level="1.4.4" data-path="determinants.html"><a href="determinants.html#cramers-rule"><i class="fa fa-check"></i><b>1.4.4</b> Cramer’s rule</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="trace.html"><a href="trace.html"><i class="fa fa-check"></i><b>1.5</b> Trace</a></li>
<li class="chapter" data-level="1.6" data-path="inverse-of-a-matrix.html"><a href="inverse-of-a-matrix.html"><i class="fa fa-check"></i><b>1.6</b> Inverse of a matrix</a></li>
<li class="chapter" data-level="1.7" data-path="matrix-multiplication-as-linear-transformation.html"><a href="matrix-multiplication-as-linear-transformation.html"><i class="fa fa-check"></i><b>1.7</b> Matrix multiplication as linear transformation</a></li>
<li class="chapter" data-level="1.8" data-path="statistics-and-proabability.html"><a href="statistics-and-proabability.html"><i class="fa fa-check"></i><b>1.8</b> Statistics and proabability</a><ul>
<li class="chapter" data-level="1.8.1" data-path="statistics-and-proabability.html"><a href="statistics-and-proabability.html#sample-statistics"><i class="fa fa-check"></i><b>1.8.1</b> Sample statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="vector-spaces.html"><a href="vector-spaces.html"><i class="fa fa-check"></i><b>2</b> Vector spaces</a><ul>
<li class="chapter" data-level="2.1" data-path="four-subspaces.html"><a href="four-subspaces.html"><i class="fa fa-check"></i><b>2.1</b> Four subspaces</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="eigenthings-and-quadratic-forms.html"><a href="eigenthings-and-quadratic-forms.html"><i class="fa fa-check"></i><b>3</b> Eigenthings and quadratic forms</a><ul>
<li class="chapter" data-level="3.1" data-path="eigenvectors-and-eigenvalues.html"><a href="eigenvectors-and-eigenvalues.html"><i class="fa fa-check"></i><b>3.1</b> Eigenvectors and eigenvalues</a></li>
<li class="chapter" data-level="3.2" data-path="diagnolization-and-similar-matrices.html"><a href="diagnolization-and-similar-matrices.html"><i class="fa fa-check"></i><b>3.2</b> Diagnolization and similar matrices</a></li>
<li class="chapter" data-level="3.3" data-path="eigenvectors-and-linear-transformations.html"><a href="eigenvectors-and-linear-transformations.html"><i class="fa fa-check"></i><b>3.3</b> Eigenvectors and linear transformations</a></li>
<li class="chapter" data-level="3.4" data-path="symmetric-matrices.html"><a href="symmetric-matrices.html"><i class="fa fa-check"></i><b>3.4</b> Symmetric matrices</a></li>
<li class="chapter" data-level="3.5" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>3.5</b> SVD</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="orthogonality.html"><a href="orthogonality.html"><i class="fa fa-check"></i><b>4</b> Orthogonality</a><ul>
<li class="chapter" data-level="4.1" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html"><i class="fa fa-check"></i><b>4.1</b> Orthogonal decomposition</a><ul>
<li class="chapter" data-level="4.1.1" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#orthogonal-complements"><i class="fa fa-check"></i><b>4.1.1</b> Orthogonal complements</a></li>
<li class="chapter" data-level="4.1.2" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#orthogonal-sets-and-orthogonal-basis"><i class="fa fa-check"></i><b>4.1.2</b> Orthogonal sets and orthogonal basis</a></li>
<li class="chapter" data-level="4.1.3" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#orthogonal-decomposition-1"><i class="fa fa-check"></i><b>4.1.3</b> Orthogonal decomposition</a></li>
<li class="chapter" data-level="4.1.4" data-path="orthogonal-decomposition.html"><a href="orthogonal-decomposition.html#best-approximation"><i class="fa fa-check"></i><b>4.1.4</b> Best approximation</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="orthonormal-sets-and-orthogonal-matrices.html"><a href="orthonormal-sets-and-orthogonal-matrices.html"><i class="fa fa-check"></i><b>4.2</b> Orthonormal sets and orthogonal matrices</a><ul>
<li class="chapter" data-level="4.2.1" data-path="orthonormal-sets-and-orthogonal-matrices.html"><a href="orthonormal-sets-and-orthogonal-matrices.html#orthogonal-matrices"><i class="fa fa-check"></i><b>4.2.1</b> Orthogonal matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="matrix-calculus.html"><a href="matrix-calculus.html"><i class="fa fa-check"></i><b>5</b> Matrix calculus</a></li>
<li class="part"><span><b>II Calculus</b></span></li>
<li class="chapter" data-level="6" data-path="taylor-series-and-expansion.html"><a href="taylor-series-and-expansion.html"><i class="fa fa-check"></i><b>6</b> Taylor series and expansion</a></li>
<li class="part"><span><b>III Applications</b></span></li>
<li class="chapter" data-level="7" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>7</b> Linear models</a><ul>
<li class="chapter" data-level="7.1" data-path="least-square-estimation.html"><a href="least-square-estimation.html"><i class="fa fa-check"></i><b>7.1</b> Least square estimation</a></li>
<li class="chapter" data-level="7.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>7.2</b> Maximum likelihood estimation</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="principle-component-analysis.html"><a href="principle-component-analysis.html"><i class="fa fa-check"></i><b>8</b> Principle component analysis</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li>
  <a href="https://github.com/rstudio/bookdown" target="blank">Written with bookdown</a>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematical Notes for Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="determinants" class="section level2">
<h2><span class="header-section-number">1.4</span> Determinants</h2>
<div id="cofactor-expansion" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Cofactor expansion</h3>
<p>The <span class="math inline">\((i, j)\text{-cofactor}\)</span> of <span class="math inline">\(A\)</span> is a number <span class="math inline">\(C_{ij}\)</span> in <span class="math inline">\(\mathbb{R}\)</span> given by</p>
<p><span class="math display">\[
C_{ij} = (-1)^{i + j} \det A_{ij}
\]</span>
where <span class="math inline">\(A_{ij}\)</span> denotes the submatrix formed by deleting the <span class="math inline">\(i\)</span>h row and <span class="math inline">\(j\)</span>th column of <span class="math inline">\(A\)</span>.</p>

<div class="theorem">
<p><span id="thm:cofactor-expansion" class="theorem"><strong>Theorem 1.3  (cofactor expansion)  </strong></span>The determinant of an <span class="math inline">\(n \times n\)</span> matrix is given by a <strong>cofactor expasion</strong> across any row or column. For example, the expansion across the <span class="math inline">\(i\)</span>th row is:</p>
<p><span class="math display">\[
\det A = a_{i1}C_{i1} + a_{i2}C_{i2} + \cdots + a_{in}C_{in} 
\]</span></p>
<p>and cross the <span class="math inline">\(j\)</span>th column is</p>
<span class="math display">\[
\det A = a_{1j}C_{1j} + a_{2j}C_{2j} + \cdots + a_{nj}C_{nj} 
\]</span>
</div>

</div>
<div id="geometric-interpretation-of-determinant" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Geometric interpretation of determinant</h3>
<p>Given matrix <span class="math inline">\(A_{n \times n}\)</span></p>
<p><span class="math display">\[
\begin{bmatrix}
a_1^{T} \\
a_2^{T} \\
\vdots \\
a_n^{T}
\end{bmatrix}
\]</span>
where <span class="math inline">\(a_1, ..., a_n\)</span> are row vectors of A. Then <span class="math inline">\(|\det A|\)</span> is the volume of parallelotope constrained by <span class="math inline">\(a_1, ..., a_n\)</span>. When <span class="math inline">\(A\)</span> is <span class="math inline">\(2\times2\)</span>, <span class="math inline">\(|\det A|\)</span> is simply the area of the parallelogram defined by two side <span class="math inline">\(a_1, a_2\)</span></p>
</div>
<div id="properties-of-determinant" class="section level3">
<h3><span class="header-section-number">1.4.3</span> Properties of determinant</h3>
<p>A list of arithmetic properties of determinants, A is an <span class="math inline">\(n\times n\)</span> matrix:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\det(A^T) = \det(A)\)</span></li>
<li><span class="math inline">\(\det(kA) = k^n \det(A)\)</span></li>
<li><span class="math inline">\(\det(AB) = \det(A)\det(B)\)</span> (although <span class="math inline">\(AB \not = BA\)</span> in general), it follows that <span class="math inline">\(\det(A^n) = \det(A)^n\)</span><br />
</li>
<li><span class="math inline">\(\det(A^{-1}) = 1 / \det(A)\)</span>, if <span class="math inline">\(A\)</span> is invertible</li>
<li>determinant is equal to the product of eigenvalues(counting multiplicity) <span class="math inline">\(\det(A) = \prod_{i=1}^n{\lambda_i}\)</span><br />
</li>
<li>If the <span class="math inline">\(i\)</span>-th row (column) in A is a sum of the <span class="math inline">\(i\)</span>-th row (column) of a matrix <span class="math inline">\(B\)</span> and the <span class="math inline">\(i\)</span>-th row (column) of a matrix <span class="math inline">\(C\)</span> and all other rows in <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are equal to the corresponding rows in <span class="math inline">\(A\)</span> (that is <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> differ from <span class="math inline">\(A\)</span> by one row only), then <span class="math inline">\(\det(A)=\det(B)+\det(C)\)</span>. This can be proven by cofactor expansion across the <span class="math inline">\(i\)</span>th row. The same applies to columns.</li>
</ol>
<p>Row operations on <span class="math inline">\(A\)</span> has the following effect on <span class="math inline">\(\det A\)</span></p>
<ul>
<li><p>if we multiply a single row in <span class="math inline">\(A\)</span> by a scalar <span class="math inline">\(k \in \mathbb{R}\)</span>, then the determinant of the new matrix is <span class="math inline">\(k\det A\)</span></p></li>
<li><p>if we exchange two rows <span class="math inline">\(a_i^T\)</span> and <span class="math inline">\(a_j^T\)</span> of <span class="math inline">\(A\)</span>, determinant becomes <span class="math inline">\(-\det A\)</span></p></li>
<li><p>Add a multiple of one row to another row has <strong>no</strong> effect on determinant</p></li>
</ul>
<p>The first two effects can be easily understood in connection with geometric meaning of determinant. As for the third one, let us represent A with row vectors</p>
<p><span class="math display">\[
A = 
\begin{vmatrix}
a_1^T \\ 
\vdots \\
a_i^T \\
\vdots \\
a_j^T \\ 
\vdots \\
a_n^T
\end{vmatrix}
\]</span>
Then <span class="math inline">\(B\)</span>, after performing replacing (add a multiple of the <span class="math inline">\(j\)</span>th row to the <span class="math inline">\(i\)</span>th row) on <span class="math inline">\(A\)</span>, becomes</p>
<p><span class="math display">\[
B = 
\begin{vmatrix}
a_1^T \\ 
\vdots \\
a_i^T + ka_j^T \\
\vdots \\
a_j^T \\ 
\vdots \\
a_n^T
\end{vmatrix}
\]</span>
By property 6 <span class="math inline">\(\det(A) = \det(B) + \det(C)\)</span> when <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> only differs from <span class="math inline">\(A\)</span> by the same row. So <span class="math inline">\(\det A\)</span> can be broke down into two parts</p>
<p><span class="math display">\[
|A| = 
\begin{vmatrix}
a_1^T \\ 
\vdots \\
a_i^T \\
\vdots \\
a_j^T \\ 
\vdots \\
a_n^T
\end{vmatrix} 
+ 
\begin{vmatrix}
a_1^T \\ 
\vdots \\
ka_j^T \\
\vdots \\
a_j^T \\ 
\vdots \\
a_n^T
\end{vmatrix} 
\]</span>
The second matrix on the right side has determinant <span class="math inline">\(0\)</span>, and <span class="math inline">\(\det A\)</span> stays the same after replacing.</p>
<p>Note that all row operations don’t change whether or not a determinant is 0, only change it by a non-zero factor or change its sign.</p>
</div>
<div id="cramers-rule" class="section level3">
<h3><span class="header-section-number">1.4.4</span> Cramer’s rule</h3>
<p>Given an <span class="math inline">\(n \times n\)</span> matrix <span class="math inline">\(A\)</span> and <span class="math inline">\(\boldsymbol{b}\)</span> in <span class="math inline">\(\mathbb{\mathbb{R^n}}\)</span>, denote <span class="math inline">\(A_i(\boldsymbol{b})\)</span> as the matrix derived by <span class="math inline">\(A\)</span> by <strong>replacing</strong> column <span class="math inline">\(i\)</span> by vector <span class="math inline">\(\boldsymbol{b}\)</span>:</p>
<p><span class="math display">\[
A_i(\boldsymbol{b}) = [\boldsymbol{a}_1 \cdots \underbrace{\boldsymbol{b}}_{\text{column} \,i} \cdots \boldsymbol{a}_n]
\]</span></p>

<div class="theorem">
<p><span id="thm:cramer" class="theorem"><strong>Theorem 1.4  (Cramer’s rule)  </strong></span>Let <span class="math inline">\(A\)</span> be an invertible <span class="math inline">\(n \times n\)</span> matrix. For any <span class="math inline">\(\boldsymbol{b}\)</span> in <span class="math inline">\(\mathbb{R^n}\)</span>, the unique solution <span class="math inline">\(\boldsymbol{x}\)</span> of <span class="math inline">\(A\boldsymbol{x} = \boldsymbol{b}\)</span> has entries given by:</p>
<span class="math display">\[
x_i = \frac{\det A_i(\boldsymbol{b})}{\det A}
\]</span>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lu-factorization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="trace.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/enixam/math-foundations/edit/master/matrix-algebra.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
